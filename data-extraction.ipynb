{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers pyserini numpy pandas matplotlib faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_python = load_dataset(\"code_search_net\", \"python\", trust_remote_code=True)\n",
    "dataset_java = load_dataset(\"code_search_net\", \"java\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract relevant fields\n",
    "filtered_data_python = [\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"language\": entry[\"language\"],\n",
    "        \"function_name\": entry[\"func_name\"],\n",
    "        \"code\": entry[\"func_code_string\"],\n",
    "        \"docstring\": entry[\"func_documentation_string\"],\n",
    "        \"file_path\": entry[\"func_path_in_repository\"],\n",
    "    }\n",
    "    for i, entry in enumerate(dataset_python[\"train\"])\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_python = pd.DataFrame(filtered_data_python)\n",
    "\n",
    "print(df_python.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract relevant fields\n",
    "filtered_data_java = [\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"language\": entry[\"language\"],\n",
    "        \"function_name\": entry[\"func_name\"],\n",
    "        \"code\": entry[\"func_code_string\"],\n",
    "        \"docstring\": entry[\"func_documentation_string\"],\n",
    "        \"file_path\": entry[\"func_path_in_repository\"]\n",
    "    }\n",
    "    for i, entry in enumerate(dataset_java[\"train\"])\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_java = pd.DataFrame(filtered_data_java)\n",
    "\n",
    "print(df_java.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_python_code(code):\n",
    "    if not isinstance(code, str):\n",
    "        return \"\"\n",
    "    # Keep docstrings but remove other comments\n",
    "    code = re.sub(r'(?<![\\'\"])#.*$', '', code, flags=re.MULTILINE)\n",
    "    # Normalize whitespace but don't remove it completely\n",
    "    code = re.sub(r'\\s+', ' ', code).strip()\n",
    "    return code\n",
    "\n",
    "def clean_java_code(code):\n",
    "    if not isinstance(code, str):\n",
    "        return \"\"\n",
    "    # Remove single-line comments\n",
    "    code = re.sub(r'//.*$', '', code, flags=re.MULTILINE)\n",
    "    # Remove multi-line comments (but preserve docstrings)\n",
    "    code = re.sub(r'/\\*(?!\\*).*?\\*/', '', code, flags=re.DOTALL)\n",
    "    # Normalize whitespace\n",
    "    code = re.sub(r'\\s+', ' ', code).strip()\n",
    "    return code\n",
    "\n",
    "df_python[\"clean_code\"] = df_python[\"code\"].apply(clean_python_code)\n",
    "df_java[\"clean_code\"] = df_java[\"code\"].apply(clean_java_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code_identifiers(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Split camelCase\n",
    "    text = re.sub(r'([a-z0-9])([A-Z])', r'\\1 \\2', text)\n",
    "    # Split snake_case\n",
    "    text = re.sub(r'_', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Apply to function names and add as a new column\n",
    "df_python['tokenized_function'] = df_python['function_name'].apply(tokenize_code_identifiers)\n",
    "df_java['tokenized_function'] = df_java['function_name'].apply(tokenize_code_identifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined text field with appropriate weighting\n",
    "def create_indexed_content(row):\n",
    "    # Give more weight to function name by repeating it\n",
    "    function_name = row['tokenized_function'] + \" \" + row['function_name']\n",
    "    function_name = function_name.strip() * 3  # Repeat for higher weight\n",
    "    \n",
    "    docstring = row['docstring'] if isinstance(row['docstring'], str) else \"\"\n",
    "    code = row['code'] if isinstance(row['code'], str) else \"\"\n",
    "    \n",
    "    # Combine with appropriate structure\n",
    "    return f\"{function_name} {docstring} {code}\"\n",
    "\n",
    "df_python['indexed_content'] = df_python.apply(create_indexed_content, axis=1)\n",
    "df_java['indexed_content'] = df_java.apply(create_indexed_content, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add language-specific prefixes to help with language filtering\n",
    "df_python['indexed_content'] = \"python_language \" + df_python['indexed_content'] \n",
    "df_java['indexed_content'] = \"java_language \" + df_java['indexed_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    # Convert to lowercase\n",
    "    query = query.lower().strip()\n",
    "    \n",
    "    # Extract language preference\n",
    "    language_prefix = \"\"\n",
    "    if \"python\" in query.lower():\n",
    "        language_prefix = \"python_language \"\n",
    "    elif \"java\" in query.lower():\n",
    "        language_prefix = \"java_language \"\n",
    "    \n",
    "    # Handle camelCase and snake_case in programming identifiers\n",
    "    # This helps match functions like \"bubbleSort\" or \"binary_search\"\n",
    "    query = re.sub(r'([a-z0-9])([A-Z])', r'\\1 \\2', query)  # Split camelCase\n",
    "    query = re.sub(r'_', ' ', query)  # Split snake_case\n",
    "    \n",
    "    # Remove special characters but preserve important coding symbols\n",
    "    query = re.sub(r'[^\\w\\s\\.\\(\\)\\[\\]_]', '', query)\n",
    "    \n",
    "    return language_prefix + query\n",
    "\n",
    "sample_query = \"Binary search in Python\"\n",
    "print(preprocess_query(sample_query)) # output: \"binary search in python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "\n",
    "df_python.to_json(\"codesearchnet_python.json\", orient=\"records\", indent=2)\n",
    "df_java.to_json(\"codesearchnet_java.json\", orient=\"records\", indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
